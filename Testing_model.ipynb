{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm_notebook,tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "\n",
    "def emb_sz_rule(n_cat:int)->int: return min(600, round(1.6 * n_cat**0.56))\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from validation import Validator\n",
    "\n",
    "from implicit.als import AlternatingLeastSquares as als\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "\n",
    "\n",
    "def dcg_at_k(r, k, method=0):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "test_df = pd.read_csv('test_df.csv')\n",
    "validator = Validator('test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = np.unique(test_df.userId.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm_notebook,tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_MF(nn.Module):\n",
    "    \n",
    "    def __init__(self,user_num,movie_num,movies):\n",
    "        torch.manual_seed(0)\n",
    "        super(My_MF, self).__init__()\n",
    "        \n",
    "        self.av_rating = -1\n",
    "        \n",
    "        self.user_num = user_num\n",
    "        self.movie_num = movie_num       \n",
    "        \n",
    "        self.user_factors = nn.Embedding(int(user_num)+1,20)\n",
    "        self.movie_factors = nn.Embedding(int(movie_num)+1,20)\n",
    "        \n",
    "        self.user_bias = nn.Embedding(int(user_num)+1,1)\n",
    "        self.movie_bias = nn.Embedding(int(movie_num)+1,1)\n",
    "        \n",
    "        self.movies = movies.long()\n",
    "        \n",
    "        self.soft = nn.Softmax(-1)\n",
    "\n",
    "        \n",
    "    def forward(self, user):\n",
    "        \n",
    "        user = user.long()\n",
    "        \n",
    "        user_embedded = self.user_factors(user).repeat(self.movies.shape[0],1)\n",
    "        movie_embedded = self.movie_factors(self.movies)\n",
    "        \n",
    "        products = (user_embedded*movie_embedded).sum(1)+self.movie_bias(self.movies).squeeze(1)\n",
    "\n",
    "        top10 = torch.argsort(products,descending=True).detach().numpy().tolist()    \n",
    "        consumed = list(train_df.loc[train_df.userId==user.item()].movieId.values)\n",
    "        \n",
    "        recom = []\n",
    "        for el in top10:\n",
    "            if el not in consumed:\n",
    "                recom.append(el)\n",
    "            if len(recom) == 10:\n",
    "                break\n",
    "                \n",
    "        return recom\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = np.unique(train_df.movieId.values)\n",
    "\n",
    "mdl = My_MF(71693, 6049,torch.Tensor(movie))\n",
    "\n",
    "mdl.load_state_dict(torch.load('models/my_als1.0.pkl',map_location='cpu'))\n",
    "users = np.unique(test_df.userId.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4211/4211 [00:49<00:00, 85.88it/s]\n"
     ]
    }
   ],
   "source": [
    "ndc1 = []\n",
    "ndc10 = []\n",
    "\n",
    "for user in tqdm(users):\n",
    "    rec_list = mdl(torch.Tensor([user]))\n",
    "    a,b = validator.valid(user,rec_list)\n",
    "    ndc1.append(a)\n",
    "    ndc10.append(b)\n",
    "   # if a> 0 or b>0:\n",
    "    #    print('yra')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.023137151879917765, 0.10094452413768583)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ndc1),np.mean(ndc10)\n",
    "#0.006979035080396459, 0.03618470745334547)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4211/4211 [00:48<00:00, 88.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.005755660629605138, 0.030977492136280562)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.load_state_dict(torch.load('models/my_als3.0.pkl',map_location='cpu'))\n",
    "ndc1 = []\n",
    "ndc10 = []\n",
    "\n",
    "for user in tqdm(users):\n",
    "    rec_list = mdl(torch.Tensor([user]))\n",
    "    a,b = validator.valid(user,rec_list)\n",
    "    ndc1.append(a)\n",
    "    ndc10.append(b)\n",
    "    \n",
    "np.mean(ndc1),np.mean(ndc10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Почему так мало?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, насколько модель хорошо выучила смещения рейтингов фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9515196308442085\n"
     ]
    }
   ],
   "source": [
    "mdl.load_state_dict(torch.load('models/my_als1.0.pkl',map_location='cpu'))\n",
    "\n",
    "diff = []\n",
    "for mov in movie:\n",
    "    bias = mdl.movie_bias(torch.Tensor([mov]).long()).item()\n",
    "    bias_real = av_rating-train_df.loc[train_df.movieId==mov,'rating'].mean()\n",
    "    \n",
    "    diff.append(np.abs(bias-bias_real))\n",
    "print(np.mean(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918402356761014\n"
     ]
    }
   ],
   "source": [
    "mdl.load_state_dict(torch.load('models/my_als4.0.pkl',map_location='cpu'))\n",
    "\n",
    "diff = []\n",
    "for mov in movie:\n",
    "    bias = mdl.movie_bias(torch.Tensor([mov]).long()).item()\n",
    "    bias_real = av_rating-train_df.loc[train_df.movieId==mov,'rating'].mean()\n",
    "    \n",
    "    diff.append(np.abs(bias-bias_real))\n",
    "print(np.mean(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И аналогично для пользователей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5737534782133606\n"
     ]
    }
   ],
   "source": [
    "mdl.load_state_dict(torch.load('models/my_als1.0.pkl',map_location='cpu'))\n",
    "\n",
    "av_rating = train_df.rating.mean()\n",
    "\n",
    "diff = []\n",
    "for user in users:\n",
    "    bias = mdl.user_bias(torch.Tensor([user]).long()).item()\n",
    "    bias_real = av_rating-train_df.loc[train_df.userId==user,'rating'].mean()\n",
    "    \n",
    "    diff.append(np.abs(bias-bias_real))\n",
    "print(np.mean(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А если загрузим модель со средним лоссом 4, то будет явно хуже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.712200143826478\n"
     ]
    }
   ],
   "source": [
    "mdl.load_state_dict(torch.load('models/my_als4.0.pkl',map_location='cpu'))\n",
    "\n",
    "av_rating = train_df.rating.mean()\n",
    "\n",
    "diff = []\n",
    "for user in users:\n",
    "    bias = mdl.user_bias(torch.Tensor([user]).long()).item()\n",
    "    bias_real = av_rating-train_df.loc[train_df.userId==user,'rating'].mean()\n",
    "    \n",
    "    diff.append(np.abs(bias-bias_real))\n",
    "print(np.mean(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
