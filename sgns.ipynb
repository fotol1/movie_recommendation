{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm_notebook,tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im begining to process a file with ratings\n",
      "indexing\n",
      "transforming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/o.lashinin/.local/lib/python3.5/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 982,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Preprocessor:\n",
    "    \n",
    "    def __init__(self,filename):\n",
    "        \n",
    "        self.file = filename\n",
    "\n",
    "        \n",
    "    def process(self,train=0.4):\n",
    "        \"\"\"\n",
    "        the main method to process file with ratings\n",
    "        \"\"\"\n",
    "        print('im begining to process a file with ratings')\n",
    "        df = pd.read_csv('ratings.csv').sort_values(by='timestamp')\n",
    "        \n",
    "        # as df is sorted by timstamp \n",
    "        sep_index = int(train * df.shape[0])\n",
    "        \n",
    "        train_df = df[:sep_index]\n",
    "        test_df = df[sep_index:]\n",
    "        \n",
    "        test_df = test_df.loc[test_df.userId.isin(train_df.userId)]\n",
    "        test_df = test_df.loc[test_df.movieId.isin(train_df.movieId)]\n",
    "        \n",
    "        users = set(train_df.userId.values)\n",
    "        movies = set(train_df.movieId.values)\n",
    "        \n",
    "        print('indexing')\n",
    "        movie_index = pd.DataFrame(movies,columns=['movieId']).reset_index()\n",
    "        movie_coder = {value: key for (key,value) in movie_index.values}\n",
    "        movie_decoder = {key: value for (key,value) in movie_index.values}\n",
    "\n",
    "        user_index = pd.DataFrame(users,columns=['userId']).reset_index()\n",
    "        user_coder = {value: key for (key,value) in user_index.values}\n",
    "        user_decoder = {key: value for (key,value) in user_index.values}\n",
    "        \n",
    "        # transform to appropriate form for als and my method\n",
    "        print('transforming')\n",
    "        train_df.userId = train_df.userId.apply(lambda x: user_coder[x])\n",
    "        train_df.movieId = train_df.movieId.apply(lambda x: movie_coder[x])\n",
    "\n",
    "        test_df.loc[test_df.movieId.isin(movies)]\n",
    "        test_df.userId = test_df.userId.apply(lambda x: user_coder[x])\n",
    "        test_df.movieId = test_df.movieId.apply(lambda x: movie_coder[x])\n",
    "        \n",
    "        print('saving')\n",
    "        train_df.to_csv('train_df.csv',index=None)\n",
    "        test_df.to_csv('test_df.csv',index=None)\n",
    "        movie_index.to_csv('movieId_index.csv',index=None)\n",
    "        user_index.to_csv('userId_index.csv',index=None)\n",
    "        \n",
    "        return 0\n",
    "        \n",
    "prep = Preprocessor('ratings.csv')\n",
    "prep.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 981,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([1,2,3]).difference([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'common_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-747-45791c7c50bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'common_texts' is not defined"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(common_texts, size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1174,  1077,    46, ...,  1344,   839, 11455])"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.movieId.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_timestamp(x):\n",
    "    a = x.values\n",
    "    a.sort(1)\n",
    "    a = a[:,0]\n",
    "    return a.tolist()\n",
    "\n",
    "q = train_df.groupby(['userId'])[['movieId','timestamp']].apply(lambda x: sort_by_timestamp(x)).reset_index()\n",
    "q.rename({0:'sequences'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for elem in q.sequences.values:\n",
    "    corpus.append(list(map(str,elem)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.549947517585679"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.unique(train_df.movieId.values).shape[0]**0.5)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v params that configure w2v model for sngs\n",
    "w2v_params = { 'sg':1, # w2v is configured for skip-gram scheme\n",
    "              'negative':10,# negative sampling is set to 10\n",
    "              #in the article the authors mentioned size equals 100\n",
    "              #but they have vocabulary with ~1M. So I have\n",
    "              #approximately 12k movies thus I set 'size' to the 4th root\n",
    "              #and just in case I'll multiply it by 2\n",
    "              'size': 20,\n",
    "              'window':5, # according to the article\n",
    "              'min_count': 1 #nothing ignored\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2vec = Word2Vec(corpus,**w2v_params)\n",
    "# So now w2v is ready to learn dependencies by skip-gram negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(79746823, 80001050)"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song2vec.train(corpus,total_examples=song2vec.corpus_count,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2vec.save('pretrained.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/o.lashinin/.local/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('441', 0.8406383395195007),\n",
       " ('316', 0.761974036693573),\n",
       " ('10', 0.7475438714027405),\n",
       " ('507', 0.7425953149795532),\n",
       " ('508', 0.7387514114379883),\n",
       " ('251', 0.7305671572685242),\n",
       " ('349', 0.7206587791442871),\n",
       " ('203', 0.7132896184921265),\n",
       " ('172', 0.7085014581680298),\n",
       " ('336', 0.7067444324493408)]"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song2vec.most_similar(['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rating = train_df.rating.apply(lambda x: (x)/5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['order'] = train_df.groupby(by=['userId'])['timestamp'].transform(lambda x: x.rank(method='min'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_(Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self.x.loc[idx]\n",
    "        \n",
    "        user = row.userId.astype(np.float32)\n",
    "        mov = row.movieId.astype(np.float32)\n",
    "        \n",
    "        most_similar = song2vec.wv.most_similar([str(int(mov))],topn=5)\n",
    "        most_similar_films = np.array([int(el[0]) for el in most_similar],dtype=np.float32)\n",
    "        most_similar_values = np.array([el[1] for el in most_similar],dtype=np.float32)\n",
    "\n",
    "        rating = row.rating.astype(np.float32)\n",
    "        \n",
    "      \n",
    "        return user,mov,most_similar_films,most_similar_values,rating\n",
    "    \n",
    "    \n",
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "       data: is a list of tuples with (example, label, length)\n",
    "             where 'example' is a tensor of arbitrary shape\n",
    "             and label/length are scalars\n",
    "    \"\"\"\n",
    "    inputs = list(zip(data))\n",
    "   # print(inputs)\n",
    "    movies_win = pad_sequence([torch.from_numpy(x[0][0]) for x in inputs],batch_first=True)\n",
    "    movies_nwin = pad_sequence([torch.from_numpy(x[0][1]) for x in inputs],batch_first=True)\n",
    "    movie = pad_sequence([torch.from_numpy(x[0][2]) for x in inputs],batch_first=True)\n",
    "\n",
    "    return movies_win,movies_nwin,movie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rank</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23061</td>\n",
       "      <td>1174</td>\n",
       "      <td>4.0</td>\n",
       "      <td>789652004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp  rank  order\n",
       "0   23061     1174     4.0  789652004     1      1"
      ]
     },
     "execution_count": 922,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset_(train_df)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                             batch_size=256,\n",
    "                                           num_workers=1,shuffle=True,\n",
    "                                           #collate_fn=collate_fn\n",
    "                                          )\n",
    "\n",
    "dloaders = {'train' : train_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_MF(nn.Module):\n",
    "    \n",
    "    def __init__(self,user_num,movie_num,av_rating):\n",
    "        torch.manual_seed(0)\n",
    "        super(My_MF, self).__init__()\n",
    "        \n",
    "        self.av_rating = av_rating\n",
    "        \n",
    "        self.user_num = user_num\n",
    "        self.movie_num = movie_num       \n",
    "        \n",
    "        self.user_factors = nn.Embedding(int(user_num)+1,20)\n",
    "        self.movie_factors = nn.Embedding(int(movie_num)+1,20)\n",
    "        \n",
    "        self.user_bias = nn.Embedding(int(user_num)+1,1)\n",
    "        self.movie_bias = nn.Embedding(int(movie_num)+1,1)\n",
    "        \n",
    "        self.soft = nn.Softmax(-1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, user, movie,ms_films,ms_values):\n",
    "        \n",
    "        user = user.long()\n",
    "        movie = movie.long()\n",
    "        ms_films = ms_films.long()\n",
    "        \n",
    "      #  print(user.shape, ' is a user.shape')\n",
    "      #  print(movie.shape, ' is a movie.shape')\n",
    "        movie_embedded = self.movie_factors(movie)\n",
    "        user_embedded = self.user_factors(user)\n",
    "      #  print(movie_embedded.shape, ' is a movie_embded.shape')\n",
    "      #  print(user_embedded.shape, ' is a user_embeded.shape')\n",
    "        \n",
    "        dot_product = (user_embedded*movie_embedded).sum(1)\n",
    "        \n",
    "        user_bias = self.user_bias(user).squeeze(1)\n",
    "        movie_bias = self.movie_bias(movie).squeeze(1)\n",
    "      #  print(user_bias.shape, ' is a shape of user_bias')\n",
    "      #  print(movie_bias.shape, ' is a shape of movie_bias')\n",
    "      #  print(dot_product.shape, ' is a shape of dot_product')\n",
    "\n",
    "        ratings = self.relu(self.av_rating + dot_product + user_bias + movie_bias)\n",
    "        \n",
    "        \n",
    "\n",
    "        reg_part = (movie_embedded**2).sum(1)+(user_embedded**2).sum(1)+user_bias**2+movie_bias**2\n",
    "       # print(reg_part.shape,' is a shape of reg_part')\n",
    "        \n",
    "        ms_embedded = self.movie_factors(ms_films)\n",
    "        #print(ms_embedded.shape,' is a shape of sim_embedded')\n",
    "        movie_repeated = movie_embedded.unsqueeze(1).repeat(1,5,1)\n",
    "       # print(movie_repeated.shape, ' is a shape of movie_repeated')\n",
    "        \n",
    "        dot_product = (ms_embedded *movie_repeated).sum(2)\n",
    "        #print(dot_product.shape, ' is a shape of dot_product')\n",
    "        \n",
    "        sgns_together = ((ms_values - dot_product)**2).sum(1)\n",
    "        \n",
    "        #print(sgns_together.shape, 'is a shape of sgns_together')\n",
    "        \n",
    "        \n",
    "        return ratings,reg_part,sgns_together\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6.6948,  5.4440,  6.0956, 10.4667,  3.0703,  1.4207,  7.1854,  1.6279,\n",
       "          6.1839,  1.0732,  4.5362,  0.0000,  8.8983,  0.0728,  0.0000,  2.5164,\n",
       "          3.1798,  0.0000,  1.5259,  7.2059,  9.0423,  5.0519,  7.2067,  0.0000,\n",
       "          0.0542, 10.5857,  0.0000,  3.4066,  3.2686,  3.8484, 12.3777,  4.7843],\n",
       "        grad_fn=<ReluBackward0>),\n",
       " tensor([37.1897, 30.1479, 40.1374, 44.2055, 42.5742, 41.3942, 46.5888, 57.4594,\n",
       "         33.2418, 38.9044, 45.0800, 46.1588, 48.4257, 41.8547, 44.4153, 25.9088,\n",
       "         28.1288, 40.2833, 34.9534, 47.2979, 44.5763, 34.4927, 44.4972, 58.1054,\n",
       "         50.5207, 48.6263, 36.1050, 35.6610, 41.0621, 59.6684, 49.0143, 56.8772],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([223.2477, 201.0573,   8.1630,  20.9485,  52.3032,  52.4362,  62.7913,\n",
       "         211.8257,  67.0896, 165.0832, 167.2347,  54.8258, 159.0081, 136.1177,\n",
       "         104.9368,  13.9133,  41.9442,  40.6457, 212.6850, 203.3205,  59.8770,\n",
       "          34.0348,  73.9590,  48.3511,  71.9242, 140.8090,  74.7485,  53.1625,\n",
       "          41.4434,  94.6060,  81.0155,  59.4092], grad_fn=<SumBackward2>))"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,(user,movie,ms_films,ms_values,ratings) in enumerate(dloaders['train']):\n",
    "    break\n",
    "#user_num = train_df.userId.max()\n",
    "#movie_num = train_df.movieId.max()\n",
    "mdl = My_MF(user_num,movie_num,round(train_df.rating.mean(),2))\n",
    "mdl(user,movie,ms_films,ms_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112465, 12387)"
      ]
     },
     "execution_count": 943,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_num,movie_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.356381058692932\n",
      "25.171711762746174\n",
      "24.264972686767578\n",
      "23.92687571676154\n",
      "23.47640671332677\n",
      "22.407146015167235\n",
      "22.357571353912352\n",
      "22.22559862136841\n",
      "22.100231170654297\n",
      "22.240929164886474\n",
      "22.321729888916014\n",
      "22.35167272567749\n",
      "22.332426223754883\n",
      "22.296225662231446\n",
      "22.270177173614503\n",
      "22.240743579864503\n",
      "22.108447456359862\n",
      "22.1380598449707\n",
      "22.14838483810425\n",
      "22.192457695007324\n",
      "22.17739845275879\n",
      "22.417572498321533\n",
      "22.462370471954344\n",
      "22.52979118347168\n",
      "22.496917781829833\n",
      "22.497417907714844\n",
      "22.34098424911499\n",
      "22.280719375610353\n",
      "22.214986419677736\n",
      "22.072260875701904\n",
      "22.120595111846924\n",
      "22.065850563049317\n",
      "22.197732238769532\n",
      "22.075315284729005\n",
      "22.226713199615478\n",
      "22.12259038925171\n",
      "22.29818407058716\n",
      "22.30522174835205\n",
      "22.282417945861816\n",
      "22.24903854370117\n",
      "22.31714672088623\n",
      "22.192077236175535\n",
      "22.071703567504883\n",
      "22.271631240844727\n",
      "22.312079257965088\n",
      "22.314600811004638\n",
      "22.209635162353514\n",
      "22.084919891357423\n",
      "22.025267066955568\n",
      "21.91879705429077\n",
      "21.92141839981079\n",
      "21.974021396636964\n",
      "22.07798957824707\n",
      "22.161136169433593\n",
      "22.20189058303833\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-976-790282f5fa61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mrem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mdl = My_MF(user_num,movie_num,round(train_df.rating.mean(),2))\n",
    "\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "optimizer = optim.SGD(mdl.parameters(), lr=1e-3)\n",
    "\n",
    "lam = 0.025\n",
    "alpha = 0.1\n",
    "\n",
    "for epoch in range(1):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    rem = []\n",
    "\n",
    "    for i,(user,movie,ms_films,ms_values,ratings) in enumerate(dloaders['train']):\n",
    "\n",
    "        ratings_pred,reg_part,sgns = mdl(user,movie,ms_films,ms_values)\n",
    "\n",
    "        loss += (((ratings.float() - ratings_pred)**2) +lam*reg_part+\\\n",
    "                alpha*sgns).mean()\n",
    "        \n",
    "\n",
    "        if i % 1 == 0 and i > 3:\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            rem.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss = 0\n",
    "            \n",
    "        if i % 20 == 19:\n",
    "            print(np.mean(rem[-100:]))\n",
    "            torch.save(mdl.state_dict(), 'models/my_als{}.pkl'.format(round(np.mean(rem[-100:]),0)))\n",
    "           # print(mdl.movie_factors(torch.Tensor([295]).long()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920, -0.3160, -2.1152,\n",
       "          0.3223, -1.2633,  0.3500,  0.3081,  0.1198,  1.2377,  1.1168, -0.2473,\n",
       "         -1.3527, -1.6959,  0.5667,  0.7935]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.user_factors(torch.Tensor([0]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112466, 12388)"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.userId.max()+1,train_df.movieId.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.72267795138889"
      ]
     },
     "execution_count": 978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16000210/256/30/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
